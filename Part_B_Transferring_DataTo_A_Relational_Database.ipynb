{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Transferring data to a relational database\n",
    "\n",
    "Joining and filtering data can be easily done by SQL queries if we have data in a relational database. So, we are now transfering the csv files as three tables in a MySQL database\n",
    "\n",
    "The following csv files were tansfered to a MySQL database \n",
    "\n",
    "1. 'distance_data_filtered.csv'\n",
    "2. 'covid_data_filtered.csv'\n",
    "3. 'population_data.csv'\n",
    "\n",
    "We'll name the database table respectively as following:\n",
    "1. `nycovidcase`\n",
    "2. `nydistance`\n",
    "3. `nypopulation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Final checking of the content before sending to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fips', 'distance', 'fips2']\n",
      "['36001', '16.23015283', '36093']\n",
      "['36001', '22.6607026', '36039']\n",
      "['36001', '23.61156982', '36095']\n",
      "['36001', '24.86162199', '36083']\n",
      "['36001', '29.44956155', '36021']\n",
      "['date', 'county', 'state', 'fips', 'cases', 'deaths']\n",
      "['2020-03-01', 'New York City', 'New York', '', '1', '0']\n",
      "['2020-03-02', 'New York City', 'New York', '', '1', '0']\n",
      "['2020-03-03', 'New York City', 'New York', '', '2', '0']\n",
      "['2020-03-04', 'New York City', 'New York', '', '2', '0']\n",
      "['2020-03-04', 'Westchester', 'New York', '36119', '9', '0']\n",
      "['county', 'population']\n",
      "['Kings', '2559903']\n",
      "['Queens', '2253858']\n",
      "['New York', '1628706']\n",
      "['Suffolk', '1476601']\n",
      "['Bronx', '1418207']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "n1=0\n",
    "n2=0\n",
    "n3=0\n",
    "\n",
    "with open ('distance_data_filtered.csv', 'r') as f1:\n",
    "    reader1 = csv.reader(f1)\n",
    "    for row1 in reader1:\n",
    "        print(row1)\n",
    "        if n1>4:\n",
    "            break\n",
    "        n1+=1\n",
    "\n",
    "        \n",
    "with open ('covid_data_filtered.csv', 'r') as f2:\n",
    "    reader2 = csv.reader(f2)\n",
    "    for row2 in reader2:\n",
    "        print(row2)\n",
    "        if n2>4:\n",
    "            break\n",
    "        n2+=1\n",
    "\n",
    "with open ('population_data.csv', 'r') as f3:\n",
    "    reader3 = csv.reader(f3)\n",
    "    for row3 in reader3:\n",
    "        print(row3)\n",
    "        if n3>4:\n",
    "            break\n",
    "        n3+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Constructing SQL for creating 3 tables in database (one for each of the data files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CREATE TABLE IF NOT EXISTS `nycovidcase` (\n",
    "  `caseid` int(5) NOT NULL AUTO_INCREMENT,\n",
    "  `date` date,\n",
    "  `county` varchar(25),\n",
    "  `state` varchar(25),\n",
    "  `fips` varchar(10),\n",
    "  `cases` int(5),\n",
    "  `death` int(5),\n",
    "   PRIMARY KEY (`caseid`)\n",
    ")\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS `nypopulation` (\n",
    "  `populationid` int(5) NOT NULL AUTO_INCREMENT,\n",
    "   `county` varchar(25),\n",
    "  `population` int(10),\n",
    "   PRIMARY KEY (`populationid`)\n",
    ")\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS `nydistance` (\n",
    "  `distanceid` int(5) NOT NULL AUTO_INCREMENT,\n",
    "   `fips1` varchar(10),\n",
    "  `distance` int(4),\n",
    "  `fips2` varchar(10),\n",
    "   PRIMARY KEY (`distanceid`)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Connecting database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pymysql\n",
    "conn = pymysql.connect(host='YourDatabaseHostNameOrLocalHost', \\\n",
    "                       port=3306, \\\n",
    "                       user='UserName', \\\n",
    "                       passwd='********', \\\n",
    "                       db='databae_name', autocommit=True)\n",
    "cur = conn.cursor(pymysql.cursors.DictCursor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Creating Table `nycovidcase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS `nycovidcase` (\n",
    "  `caseid` int(5) NOT NULL AUTO_INCREMENT,\n",
    "  `date` date,\n",
    "  \n",
    "  `county` varchar(25),\n",
    "  `state` varchar(25),\n",
    "  `fips` varchar(10),\n",
    "  `cases` int(5),\n",
    "  `death` int(5),\n",
    "   PRIMARY KEY (`caseid`)\n",
    ");\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Creating Table `nydistance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS `nydistance` (\n",
    "  `distanceid` int(5) NOT NULL AUTO_INCREMENT,\n",
    "   `fips1` varchar(10),\n",
    "  `distance` float(4),\n",
    "  `fips2` varchar(10),\n",
    "   PRIMARY KEY (`distanceid`)\n",
    ");\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Creating Table `nypopulation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Table nypopulation\n",
    "cur.execute('''\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS `nypopulation` (\n",
    "  `populationid` int(5) NOT NULL AUTO_INCREMENT,\n",
    "   `county` varchar(25),\n",
    "  `population` int(10),\n",
    "   PRIMARY KEY (`populationid`)\n",
    ");\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a.  Checking `covid_data_filtered.csv` as a list of dictionary before inserting rows into database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2020-03-01', 'county': 'New York City', 'state': 'New York', 'fips': '', 'cases': '1', 'deaths': '0'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('covid_data_filtered.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Inserting rows into `nycovidcase` by utilizing 'block size' concept\n",
    "\n",
    "Although the csv files here are not too large,still using this concept of sending data in chunks for the sake of a'good practice' so that the codes remain scalable for large data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block size: 4000 - total time : 1.097567081451416\n"
     ]
    }
   ],
   "source": [
    "import pymysql,csv,time,datetime\n",
    "\n",
    "# preparing 'data' object(a list of dictionary) for inserting rows into the corresponding database table\n",
    "\n",
    "with open('covid_data_filtered.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    #print(data[0], '\\n')\n",
    "\n",
    "    \n",
    "# Inserting rows (in blocks, for faster operations) from csv into database table \n",
    "\n",
    "sql = '''\n",
    "INSERT INTO `nycovidcase`\n",
    "(\n",
    "`date`, `county`,`state`,`fips`,\n",
    "`cases`,`death`\n",
    ")\n",
    " VALUES (%s,%s,%s,%s,%s,%s);\n",
    " ''' \n",
    "\n",
    "tokens =[]\n",
    "n= 0 \n",
    "i=0\n",
    "blocksizes = [4000]\n",
    "\n",
    "for bs in blocksizes:\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for line in data:\n",
    "        tokens.append((line[\"date\"],\n",
    "                  line[\"county\"],\n",
    "                  line[\"state\"],\n",
    "                  line[\"fips\"],\n",
    "                  line[\"cases\"],\n",
    "                  line[\"deaths\"]))\n",
    "        if i % bs == 0:\n",
    "            n+=1\n",
    "            bstart = time.time()\n",
    "            cur.executemany(sql,tokens)\n",
    "            conn.commit()\n",
    "            tokens = []\n",
    "        i+=1\n",
    "    print (\"block size: \" + str(bs) + \" - total time : \" + str(time.time() - start))\n",
    "    if len(tokens) > 0:\n",
    "        cur.executemany(sql,tokens)\n",
    "        conn.commit()\n",
    "    \n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c.  Checking `distance_data_filtered.csv` as a list of dictionary before inserting rows into database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fips': '36013', 'distance': '359', 'fips2': '36103'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking csv content as a list of dictionary before inserting them into database table\n",
    "import csv\n",
    "c=0\n",
    "with open('distance_data_filtered.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5d. Inserting rows into `nycdistance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block size: 400 - total time : 0.8525772094726562\n"
     ]
    }
   ],
   "source": [
    "import pymysql,csv,time,datetime\n",
    "\n",
    "# preparing 'data' object(a list of dictionary) for inserting rows into the corresponding database table\n",
    "\n",
    "c=0\n",
    "with open('distance_data_filtered.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    # print(data[0], '\\n')\n",
    "\n",
    "    \n",
    "# Inserting rows (in blocks, for faster operations) from csv into database table \n",
    "sql = '''\n",
    "INSERT INTO `nydistance`\n",
    "(\n",
    "`fips1`, `distance`,`fips2`\n",
    ")\n",
    " VALUES (%s,%s,%s);\n",
    " ''' \n",
    "\n",
    "tokens =[]\n",
    "n= 0 \n",
    "i=0\n",
    "blocksizes = [400]\n",
    "\n",
    "for bs in blocksizes:\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for line in data:\n",
    "        tokens.append((line[\"fips\"],\n",
    "                  line[\"distance\"],\n",
    "                  line[\"fips2\"]))\n",
    "        if i % bs == 0:\n",
    "            n+=1\n",
    "            bstart = time.time()\n",
    "            cur.executemany(sql,tokens)\n",
    "            conn.commit()\n",
    "            tokens = []\n",
    "        i+=1\n",
    "    print (\"block size: \" + str(bs) + \" - total time : \" + str(time.time() - start))\n",
    "    if len(tokens) > 0:\n",
    "        cur.executemany(sql,tokens)\n",
    "        conn.commit()\n",
    "    \n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5e.  Checking `distance_data_filtered.csv` as a list of dictionary before inserting rows into database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'county': 'Kings', 'population': '2559903'}, {'county': 'Queens', 'population': '2253858'}, {'county': 'New York', 'population': '1628706'}, {'county': 'Suffolk', 'population': '1476601'}, {'county': 'Bronx', 'population': '1418207'}, {'county': 'Nassau', 'population': '1356924'}, {'county': 'Westchester', 'population': '967506'}, {'county': 'Erie', 'population': '918702'}, {'county': 'Monroe', 'population': '741770'}, {'county': 'Richmond', 'population': '476143'}, {'county': 'Onondaga', 'population': '460528'}, {'county': 'Orange', 'population': '384940'}, {'county': 'Rockland', 'population': '325789'}, {'county': 'Albany', 'population': '305506'}, {'county': 'Dutchess', 'population': '294218'}, {'county': 'Saratoga', 'population': '229863'}, {'county': 'Oneida', 'population': '228671'}, {'county': 'Niagara', 'population': '209281'}, {'county': 'Broome', 'population': '190488'}, {'county': 'Ulster', 'population': '177573'}, {'county': 'Rensselaer', 'population': '158714'}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking csv content as a list of dictionary before inserting them into database table\n",
    "with open('population_data.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    print(data[0:21], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5f. Inserting rows into `nypopulation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block size: 20 - total time : 0.2222902774810791\n"
     ]
    }
   ],
   "source": [
    "import pymysql,csv,time,datetime\n",
    "\n",
    "# preparing 'data' object(a list of dictionary) for inserting rows into the corresponding database table\n",
    "\n",
    "c=0\n",
    "with open('population_data.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    # print(data[0], '\\n')\n",
    "\n",
    "\n",
    "# Inserting rows (in blocks, for faster operations) from csv into database table \n",
    "\n",
    "sql = '''\n",
    "INSERT INTO `nypopulation`\n",
    "(\n",
    " `county`,`population`\n",
    ")\n",
    " VALUES (%s,%s)\n",
    " ''' \n",
    "\n",
    "tokens =[]\n",
    "n= 0 \n",
    "i=0\n",
    "blocksizes = [20]\n",
    "\n",
    "for bs in blocksizes:\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for line in data:\n",
    "        tokens.append((line[\"county\"],\n",
    "                  line[\"population\"]))\n",
    "        if i % bs == 0:\n",
    "            n+=1\n",
    "            bstart = time.time()\n",
    "            cur.executemany(sql,tokens)\n",
    "            conn.commit()\n",
    "            tokens = []\n",
    "        i+=1\n",
    "    print (\"block size: \" + str(bs) + \" - total time : \" + str(time.time() - start))\n",
    "    if len(tokens) > 0:\n",
    "        cur.executemany(sql,tokens)\n",
    "        conn.commit()\n",
    "    \n",
    "cur.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
